# LLM Provider (choose one: ollama, claude, simple)
# - ollama: Local LLM (FREE, best for self-hosting)
# - claude: Anthropic Claude API (requires credits)
# - simple: Simple keyword extraction (no AI)
LLM_PROVIDER=ollama

# Ollama Settings (if using ollama)
OLLAMA_MODEL=llama3.2:3b

# Anthropic API Key (if using claude)
ANTHROPIC_API_KEY=
